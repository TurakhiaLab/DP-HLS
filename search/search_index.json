{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"DP-HLS: A High-Level Synthesis Framework for Accelerating Dynamic Programming Algorithms in Bioinformatics","text":""},{"location":"index.html#dp-hls-video-tutorial","title":"DP-HLS Video Tutorial","text":""},{"location":"index.html#introduction","title":"Introduction","text":"<p>Welcome to the official wiki of DP-HLS. DP-HLS is a framework designed to simplify and accelerate the development of a broad set of bioinformatically relevant DP algorithms based on the 2-D DP paradigm using High-Level Synthesis (HLS). Built with the AMD Vitis HLS tool, DP-HLS offers extensive customizability, enabling users to create and implement FPGA-accelerated kernels tailored to their specific applications.</p>"},{"location":"index.html#2-d-dynamic-programming-paradigm","title":"2-D Dynamic Programming Paradigm","text":"<p>Many bioinformatics problems involve comparing linear biological sequences (DNA, RNA, proteins) to identify similarities and differences. A common approach to this problem is using 2-D dynamic programming (DP) algorithms (2-D DP paradigm), which typically consists of three steps: i) initialization, ii) matrix fill, and iii) traceback. </p> <p>The initialization step arranges the two sequences being compared on a 2-D grid, called DP matrix, with one sequence along the horizontal axis and the other along the vertical axis. The first row and column are initialized with predefined scores. Next, in the matrix fill step, a recursive formula is used to score each cell based on its three neighboring cells: above, left, and diagonal, allowing for \u2019gaps\u2019 in sequences. Finally, the traceback step, which is optional in some algorithms, recovers the path in the DP matrix corresponding to the sequence of decisions giving the overall optimal score. </p>"},{"location":"index.html#variations-in-2-d-dynamic-programming-algorithms","title":"Variations in 2-D Dynamic Programming algorithms","text":"<p>Variations in general paradigm of 2-D Dynamic Programming has led to wide variety of algorithms used by bioinformatics tools in various applications. The table below lists some of the famous algorithms used in bioinformatics which is caused due to some variations in the scoring, initialization and traceback part of the general DP algorithmic template. These variations are described in Customize new kernels section below.</p> Sl No. Input Alphabets Kernels State-of-the-art Tools Applications Modifications in DP-HLS 1 DNA Global Linear Alignment (Needleman-Wunsch) BLAST, EMBOSS Stretcher Similarity Search 2 DNA Global Affine Alignment (Gotoh) BLAST, EMBOSS Needle Similarity Search with gaps Scoring 3 DNA Local Linear Alignment (Smith-Waterman) BLAST, FASTA, BLAT Gene finding, Motif detection Initialization and Traceback 4 DNA Local Affine Alignment (Smith-Waterman-Gotoh) BLAST, LASTZ Gene finding, Motif detection Scoring, Initialization and Traceback 5 DNA Global Two-piece Affine Alignment Minimap2 Long Read Alignment Scoring 6 DNA Overlap Alignment CANU, Flye Whole Genome Assembly Initialization and Traceback 7 DNA Semi-global Alignment BWA-MEM Whole Genome Assembly Initialization and Traceback 8 Seq. Profiles Profile Alignment CLUSTALW, MUSCLE Multiple Sequence Alignment Sequence Alphabet and Scoring 9 Complex Nos. Dynamic Time Wrapping Algorithm (DTW) SquiggleKit Basecalling Sequence Alphabet and Scoring 10 DNA Viterbi Algorithm (PairHMM) HMMER, Augustus Remote Homology Search Scoring (no Traceback) 11 DNA Banded Global Linear Alignment BLAST, Bowtie Fast local alignment Scoring and Initialization 12 DNA Banded Local Affine Alignment Minimap2 Long read alignment Initialization, Scoring (no Traceback) 13 DNA Banded Global Two-piece Affine Alignment Minimap2 Long read alignment Scoring, Initialization and Traceback 14 Integers Semi-global DTW (sDTW) SquiggleFilter, RawHash Basecalling Sequence Alphabet and Scoring 15 Amino acids Local Linear Alignment with protein sequences EMBOSS Water, BLASTp, DIAMOND Protein Local Alignment Sequence Alphabet and Scoring"},{"location":"index.html#dp-hls-framework","title":"DP-HLS Framework","text":"Image above shows steps of execution from user configuration to deployment of kernels Image above illustrates the layout of DP-HLS Front-end component with customizable and parallelizable blocks <p>The DP-HLS framework is composed of two main components: the front-end and the back-end. The front-end component allows users to specify or customize new kernels in C/C++ by modifying certain parameters and code blocks. After configuring the HLS framework to create a kernel as per your usecases, then user needs to simulate, verify and synthesize the kernel. Once done, the kernel is ready to be deployed to FPGA after incorporating the host code. The above figure depicts the various stages of the front-end design flow. </p> <p>The back-end component of the DP-HLS framework contains a fixed set of HLS directives or pragmas that provide the HLS compiler with the necessary hints to efficiently map the front-end kernel design specification into an optimized RTL implementation  to be deployed to FPGA without requiring digital design expertise. </p>"},{"location":"index.html#features","title":"Features","text":"<ol> <li>Easy customization of algorithms: HLS-based open-source framework streamlines the creation of FPGA accelerators for new algorithms. To implement any custom algorithm, only the scoring functions and a few parameters need to be modified without requiring an in-depth RTL or digital design experience.</li> <li>Easy deployment into hardware: The framework allows the user to implement highly customized FPGA kernels to deploy within days, whereas developing in HDL takes months.</li> <li>Supports complex 2-D DP based algorithms: DP-HLS supports the creation of Viterbi Algorithm, Multiple Sequence Alignment and Dynamic Time Warping Algorithm based kernels in a common framework for the first time. </li> <li>Faster kernels compared to baselines: DP-HLS based kernel implementation showed up to 32x improvements in throughput over CPU baselines and comparable results (within 7.7% to 16.8% margin) to hand-crafted RTL implementations, with the added benefit of easier design configurability.</li> </ol>"},{"location":"index.html#quick-start","title":"Quick Start","text":"<p>To create, customize and deploy your own kernel on FPGA using DP-HLS framwork, it requires a series of steps to be executed. We have already developed pre-built templates of some of the well known algorithms listed in table 1. These pre-built templates are simulated using standard C++, synthesized using AMD Vitis HLS 2021.2 toolchain on 8-core Amazon EC2 z1d instance and deployed on Amazon EC2 F1 instance based FPGA.</p> <p>The following sections mentions the steps to quickly simulate, synthesize and deploy global affine kernel which incorporates Needleman-Wunsch algorithm with affine gap penalty. Similar steps need to be followed for other pre-built kernel templates as well. To create and execute your own custom kernel, please refer to the sections which describes all possible commands and parameters supported by DP-HLS - Customize new kernels, Build and simulate new kernels and Synthesize and deploy new kernels. </p>"},{"location":"index.html#step-0-create-aws-instances","title":"Step 0: Create AWS instances","text":"<p>To use our DP-HLS framework quickly to build and run the kernels, it would be preferrable to use AWS instances which comes with the AWS FPGA Developer AMI containing AMD Vitis 2021.2. </p>"},{"location":"index.html#step-1-clone-the-dp-hls-repository-from-github","title":"Step 1: Clone the DP-HLS repository from GitHub","text":"<p>The DP-HLS repo can be cloned using the following commands.</p> <p><pre><code>git clone https://github.com/TurakhiaLab/DP-HLS.git\n</code></pre> or <code>ssh</code> to : <pre><code>git clone git@github.com:TurakhiaLab/DP-HLS.git\n</code></pre></p>"},{"location":"index.html#step-2-install-the-required-dependencies","title":"Step 2: Install the required dependencies","text":"<p>Please make sure the following dependencies are installed in your system.</p> <ul> <li>g++ &gt;= 4.8.5</li> <li>Python &gt; 3.6</li> </ul>"},{"location":"index.html#step-3-build-and-simulate-the-kernel","title":"Step 3: Build and simulate the kernel","text":"<p>Once the repository is cloned and dependencies are installed, run the following command to build and simulate the kernel.</p> <pre><code>mkdir build &amp;&amp; cd build\ncmake ..\nmake global_affine \n</code></pre>"},{"location":"index.html#step-4-synthesize-the-kernel","title":"Step 4: Synthesize the kernel","text":"<p>Once the build is complete, you need to configure the file <code>config.json</code> under <code>demo/global_affine</code> by providing the DP-HLS folder path. This pre-configured JSON file will compile and synthesize the Global Affine kernel with <code>MAX_QUERY_LENGTH</code> and <code>MAX_REFERENCE_LENGTH</code> as 256 each along with 32 PEs, 2 Blocks, and 1 Compute Unit. The input clock frequency is set to 250 MHz. </p> <p><pre><code>{\n    \"size\": {\n        \"max_problem_size\": [\n            {\"max_query_length\": 256, \"max_reference_length\": 256}\n        ],\n        \"pe_num\": [32],\n        \"blocks\": [2],\n        \"cu\": [1]\n    },\n    \"kernel\": {\n        \"name\": \"seq_align_multiple_static\",\n        \"clock_frequency\": 250000000\n    },\n    \"design\": {\n        \"path_params\": \"&lt;dp_hls_root&gt;/DP-HLS/demo/global_affine/design\",\n        \"path_frontend\": \"&lt;dp_hls_root&gt;/demo/global_affine/design/kernel_global_affine.cpp\",\n        \"dp-hls_root\": \"&lt;dp_hls_root&gt;\",\n        \"host_program\": \"&lt;dp_hls_root&gt;/DP-HLS/src/hosts/host_ocl_global.cpp\"\n    },\n    \"output_path\": \"&lt;dp_hls_root&gt;/demo/global_affine/output/compile\",\n    \"output_name\": \"global_affine\",\n    \"build\": {\n        \"build_type\": \"hw\"\n    },\n    \"vitis_hls\": {\n        \"cosim_testbench\": \"&lt;dp_hls_root&gt;/DP-HLS/testbench/test_csim_global_affine.cpp\",\n        \"output_path\": \"&lt;dp_hls_root&gt;/demo/global_affine/output/cosim\",\n        \"export_design\": 0\n    }\n}\n</code></pre> Once the JSON file is configured as mentioned above, run the following command for compiling and synthesizing the Global Affine kernel. </p> <pre><code>python /home/centos/workspace/DP-HLS/py-hls/parallel_compile.py --config &lt;dp_hls_root&gt;/demo/global_affine/config.json --compile True --num_workers 1 --all True\n</code></pre> <p>After completion of this step, an <code>.xclbin</code> file will be generated which is the bitstream file, used for deploying the kernel on the FPGA device. </p>"},{"location":"index.html#step-5-deploy-the-kernel-on-fpga","title":"Step 5: Deploy the kernel on FPGA","text":"<p>Once the compilation is done and the <code>.xclbin</code> bitsteram is generated, you need to create an AFI to deploy the kernel. This can be done on any platform. However, we prefer using AWS instances which has AWS FPGA Developer AMI containing AMD Vitis 2021.2.  </p> <p>First you need to create a S3 bucket for the design checkpoint (DCP) and the logs. </p> <p>1. Create AFI</p> <p>Execute the following commands to create an AFI for kernel deployment. </p> <pre><code>git clone https://github.com/aws/aws-fpga.git  # Clone the AWS FPGA Repo\nsource aws-fpga/vitis_setup.sh     # Setup the Vitis HLS\ncd &lt;dp_hls_root&gt;/demo/global_affine/output/compile &amp;&amp; &lt;aws_fpga_repo_path&gt;/Vitis/tools/create_vitis_afi.sh -xclbin=./build_dir.hw.xilinx_aws-vu9p-f1_shell-v04261818_201920_3/seq_align_kernel.xclbin -o=./global_affine -s3_bucket=&lt;s3_bucket_name&gt; -s3_dcp_key=&lt;s3_dcp_folder&gt; -s3_logs_key=&lt;s3_logs_folder&gt;\n</code></pre> <p>2. Waiting for the AFI to ready </p> <p>You can check whether an AFI is ready using <code>aws ec2 describe-fpga-images --fpga-image-ids &lt;AFI ID&gt;</code>. The AFI is ready to use if the status of the code is available, as shown below. </p> <pre><code>...\n\"State\": {\n    \"Code\": \"available\"\n},\n...\n</code></pre> <p>3. Run the kernel </p> <p>You can now run the kernel on AWS F1 FPGA based instances. </p> <p>AWS instance creation: AWS F1 instance creation can be done with two methods. The first method is to change the instance type of the development instance to be <code>f1.2xlarge</code>. The another method is to create an EFS that are capable share files across multiple instances; then you create a new F1 instance with AWS-FPGA repo cloned in it and upload the compilation output folder to the EFS for sharing between the Development and Deployment instance. </p> <p>Once you are on the F1 instance, after you can access the compiled bitstream, you can start the kernel by running:</p> <pre><code>./dp-hls_host global_affine.awsxclbin\n</code></pre>"},{"location":"index.html#customize-new-kernels","title":"Customize new kernels","text":"<p>This section mention detailed steps to create and customize your own kernel based on specific requirements. Once the kernels are customized, then it will be ready for simulation, synthesis and deployment. We also mention the details on how to build and simulate your kernel to verify the implementation in the section Build and simulate new kernels as well as how to synthesize and deploy it on AWS F1 FPGA instances (FPGA device in which we tested our pre-built kernel templates) in the section Synthesize and deploy new kernels.</p>"},{"location":"index.html#step-1-understanding-variations-in-2-d-dynamic-programming-paradigm","title":"Step 1: Understanding variations in 2-D Dynamic Programming paradigm","text":"<p>Before starting, it is preferred to go through and understand the existing variations in 2-D DP paradigm before diving deep into the customization step. </p> <p>All kernels follow a general template for 2-D dynamic programming paradigm. However, subtle variations lead to creation of different types of algorithms for different usecases (check out algorithms and their corresponding variations listed in table 1). Some of the variations are mentioned in subsequent sections below. </p>"},{"location":"index.html#variations-in-initialization-step","title":"Variations in Initialization Step","text":"<p>For the execution of dynamic progamming, the first row and column of the 2-D DP matrix needs to be initialized. User can provide their own initial scores for the first row and column depending on the usecases. Depending on which traceback strategy (described below) is used, the scores could be a constant (e.g., 0 or -\u221e) or a function of the gap penalties.</p>"},{"location":"index.html#variations-in-traceback-step","title":"Variations in Traceback Step","text":"<p>Traceback step determine the path that results in the optimal score. While the recurrence scoring equations specify the optimal transitions on a path, depending on the usecases, the traceback strategy determines where to start and end the traceback path. There are variations seen in the traceback step for mainly four categories of alignments algorithms: global, local, semi-global, and overlap. User can have their own traceback strategy depending on their requirements. </p> <ol> <li>Global strategy performs end-to-end comparison of sequences, with traceback starting from the bottom-right cell of the 2-D DP matrix to the top-left cell. This is commonly used when two corresponding sequences, e.g., gene sequences, are being compared. </li> <li>Local strategy finds the most similar subsequences and is ideally suited for identifying conserved motifs or functional regions in sequences. Here, the traceback begins from the highest-scoring cell and stops at a 0-scoring cell.</li> <li>Semi-global strategy allows paths spanning one sequence end-to-end with a sub-sequence of the other. Here, the traceback begins from the highest-scoring cell in the bottom row of the 2-D DP matrix and continues to the top row. </li> <li>Overlap strategy matches sub-sequences at the beginning of one sequence and at the end of the other. This algorithm finds applications in genome assembly. Here, the traceback starts from the highest-scoring cell in the rightmost column (bottom row) of the 2-D DP matrix and continues to the top row (leftmost column).</li> </ol>"},{"location":"index.html#variations-in-scoring-logic","title":"Variations in Scoring Logic","text":"<p>Scoring of the cells in the 2-D DP paradigm refers to the recurrence equations used to calculate the individual scores of cells in the 2-D grid. Equations reward matches or similarities of characters in the two sequences being compared and penalize mismatches or gaps. Several variations of scoring strategies are commonly used in bioinformatics applications as shown in the above figure. User can specify their own scoring equation for their custom algorithmic requirement. </p>"},{"location":"index.html#variations-in-input-alphabets","title":"Variations in Input Alphabets","text":"<p>An alphabet refers to the set of characters used to represent the sequences being compared, such as DNA, RNA, or protein sequences, which consists of 4 or 20 characters, although variations may exist. In DNA based kernel algorithms, sequences are represented as 4 different nucleotides, with extra N representing the ambiguous bases. Multiple sequence alignment inputs are represented as profiles which is a tuple of 5 (21) integers, referring to the frequencies of 4 nucleotides. For RNA based alignments, inputs alphabets are represented as 20 different characters corresponding to amino acids. Dynamic Time Warping based alignments, used in signal processing to compare two time-series signals, uses real or complex number values as input alphabets. </p> <p>Hence for different types of algorithms, there can be differences in types of input alphabets and their representation, provided by the user. </p>"},{"location":"index.html#step-2-customize-data-types-and-parameters","title":"Step 2: Customize data types and parameters","text":"<p>Step 2-6 describes how to configure and customize your own kernel. The customization steps involve changes in few parameters as well as addition/modification of few code blocks as mentioned. Once you are aware of the variations that exists and how it leads to different algorithms (described in step 1), it will be easier to configure parameters. </p> <p>DP-HLS framework supports custom data types of all kernels with variable precision for scoring, traceback, and internal logic indices. This flexibility enables users to attain optimal computational efficiency according to the specific needs of their kernels. </p> <p>The possible datatype and parameter customization supported by DP-HLS is described in this step below.</p>"},{"location":"index.html#1-modify-sequence-alphabet","title":"1. Modify Sequence Alphabet","text":"<p>To modify the sequence alphabets of the inputs of custom kernels, define an arbitrary user-defined datatype <code>char_t</code> as follows. The example mentions a 2-bit precision integer used to define char_t. This alphabet represents the four nucleotide bases <code>A</code>,<code>C</code>,<code>G</code>,<code>T</code> within the custom kernels requiring DNA sequences as input. </p> <pre><code>typedef ap_uint&lt;2&gt; char_t;\n</code></pre> <p>To define input alphabets for Dynamic Time Warping (DTW) kernels, DP-HLS requires user to define a struct (shown below) consisting of two 32-bit fixed-point numbers to represent the real and imaginary parts of the two temporal signals (which take complex values) being compared by the kernel.</p> <pre><code>struct char_t_st {\n    ap_fixed &lt;32,26&gt; real, imag;\n    };\n\ntypedef char_t_st char_t \n</code></pre>"},{"location":"index.html#2-modify-scoring-layers","title":"2. Modify Scoring Layers","text":"<p>To design and customize a 2-D DP kernel that involves multiple recurrence equations, each computing a unique value per cell, DP-HLS provides a variable called <code>N_LAYERS</code> which configures the number of unique values computed and stored per cell of the DP matrix. </p> <p>For example, for affine-gap penalty based kernels, which uses 3 recurrence equations, <code>N_LAYERS</code> is set to 3. For two-level affine-gap penalty based kernels, set it to 5 for 5 layers of DP-matrix, each governed by one recurrence equation. </p>"},{"location":"index.html#3-modify-scoring-parameters","title":"3. Modify Scoring Parameters","text":"<p>For a custom kernel, specify arbitrary number of scoring parameters used by the kernels, each of arbitrary data types in a C/C++ struct called <code>ScoringParams</code>. The following example shows the definition of <code>ScoringParams</code> for Global Linear Kernel which uses 3 parameters: match, mismatch and one linear gap penalty. </p> <pre><code>struct ScoringParams { \n    type_t mismatch;\n    type_t match;\n    type_t linear_gap;\n} params;\n</code></pre> <p>Viterbi algorithm for pairHMMs requires three hidden states (M-Match/Mismatch, I-Insertion and D-Deletion) and a total of 27 parameters including two transition probabilities between three hidden states and 5x5 matrix storing the emission probabilities for all pairs of character (<code>A</code>,<code>C</code>,<code>G</code>,<code>T</code>) in the M states. The following example illustrates the definition of struct <code>ScoringParams</code> used for designing Viterbi Algorithm. </p> <pre><code>struct ScoringParams {\n    type_t log_mu ;\n    type_t log_lambda ;\n    type_t emission [5][5];\n} params ;\n</code></pre>"},{"location":"index.html#4-specify-maximum-sequence-lengths","title":"4. Specify Maximum Sequence Lengths","text":"<p>DP-HLS requires users to set the maximum sequence lengths for the input reference and query using <code>MAX_REFERENCE_LENGTH</code> and <code>MAX_QUERY_LENGTH</code> to determine the memory sizes for storing sequences and traceback pointers on the FPGA device. This allows user to execute kernels with sequence lengths smaller than or equal to maximum configured lengths without reimplementing the kernel. </p>"},{"location":"index.html#5-specify-traceback-pointer-data-types-and-states","title":"5. Specify Traceback Pointer data types and states","text":"<p>To specify the datatype for traceback pointers, define the datatype <code>tb_t</code> as arbitrary precision integers (<code>ap_uint&lt;2&gt;</code> for Global Linear Kernel and <code>ap_uint&lt;4&gt;</code> for Global Affine Kernel since both kernels require a 2-bit and 4-bit traceback pointer, respectively). 2-bit traceback pointer is used to point any one position out of 3 positions (up, left and diagonal) for each of the cell. Among 4-bit traceback pointer used by Global Affine, 2-bit is used for direction mentioned above. Upper 2 bits are used for choosing one layer out of three layers in affine gap penalty based kernels. </p> <p>The traceback logic in the final step of DP algorithms is equivalent to a finite state machine (FSM) in which the current state <code>tb_curr_state</code> and the traceback matrix determine the next state <code>tb_next_state</code>, and the state transitions translate to the traceback path. The users are required to enumerate the possible traceback states in the variable <code>TB_STATE</code> as shown below.</p> <p>The following example enumerates three states \u2014 <code>MM</code>, <code>INS</code>, and <code>DEL</code> \u2014 in the Global Linear kernel representing the three possible states of traceback pointers based on its recurrence equation.</p> <pre><code>enum TB_STATE {\n    MM , INS , DEL\n} tb_next_state, tb_curr_state ;\n</code></pre> <p>The following example shows for the Global Affine kernel, where the two additional recurrence equations for long gap scores <code>LONG_INS</code> and <code>LONG_DEL</code> (long deletion and long insertion respectively) each add a traceback state. </p> <pre><code>enum TB_STATE {\n    MM , INS , DEL ,\n    LONG_INS , LONG_DEL\n} tb_next_state, tb_curr_state ;\n</code></pre>"},{"location":"index.html#6-specify-band-width-for-banding-kernels","title":"6. Specify Band Width (for banding kernels)","text":"<p>DP-HLS allows user to opt the banding search space pruning strategy in their custom kernel by setting the macro <code>BANDING</code> to <code>FIXED</code> and <code>BANDWIDTH</code> to the desired band size. <code>BANDING</code> is set to <code>RECTANGULAR</code> by default or if no banding is needed.</p>"},{"location":"index.html#step-3-initialize-row-and-column-scores","title":"Step 3: Initialize row and column scores","text":"<p>Once the parameters are specified based on requirements (described in step 2), now its time to add/modify code blocks for initialization, scoring and traceback logic for your own custom kernel. This step shows how to add your own column and row initialization scores as the first step in the 2-D DP paradigm. </p> <p>To provide the initial row and column scores to the custom kernel for the initial step, specify the values of the 2-D arrays <code>init_row_scr</code> and <code>init_col_scr</code>. Each array is of dimensions <code>MAX_REFERENCE_LENGTH \u00d7 N_LAYERS</code> and <code>MAX_QUERY_LENGTH \u00d7 N_LAYERS</code>, respectively. The users should only specify the values of these arrays, as the DP-HLS\u2019s back-end automatically copies them to the device at runtime.</p> <p>The following example illustrates the row and column initialization of Global Linear Kernel. It has a single scoring layer at index 0 whose first row and column are initialized to account for gaps at the start of the alignment.</p> <pre><code>type_t gap = scoring_params.linear_gap ;\nfor ( int i = 0; i &lt; MAX_REFERENCE_LENGTH ; i ++) {\n    init_row_scr [ i ][0] = i * gap ; }\nfor ( int i = 0; i &lt; MAX_QUERY_LENGTH ; i ++) {\n    init_col_scr [ i ][0] = i * gap ; }\n</code></pre>"},{"location":"index.html#step-4-specify-scoring-function","title":"Step 4: Specify Scoring function","text":"<p>The second step after initialization is the scoring of the DP matrix. To execute this step, user needs to provide their own recurrence equations to be executed by each Processing Elements (PE) and filled up in each of the cells of the DP matrix. </p> <p>Specify the recurrence equations for computing the score and traceback pointer for a single cell (i, j), located at row <code>i</code> and column <code>j</code> of the DP matrix, in a specific function, <code>PE_func</code>. </p> <p>The following example code shows the scoring equations computed by PEs for the Local Linear kernel. The arrays <code>dp_mem_up</code>, <code>dp_mem_diag</code>, and <code>dp_mem_left</code>, are the inputs to <code>PE_func</code> and populated with cell scores automatically by the DP-HLS backend for cells at positions up (i-1, j), diagonal (i-1, j-1) and left (i, j-1) of the current cell (i, j). Likewise, the i<sup>th</sup> query character and the j<sup>th</sup> reference character are also automatically available to the input of <code>PE_func</code> as <code>lc_qry_val</code> and <code>lc_ref_val</code>, respectively. At the end of the function call, valid scores and traceback pointers for cell (i, j) must be stored to <code>wt_scr</code> and <code>wt_tbp</code>.</p> <pre><code>// Inside Local Linear PE_func\n// Compute the upper , left , and diagonal scores\n\ntype_t linear_gap = params . linear_gap ;\ntype_t ins = dp_mem_left [0] + linear_gap ;\ntype_t del = dp_mem_up [0] + linear_gap ;\ntype_t match = dp_mem_diag [0] + ( lc_qry_val == lc_ref_val ) ? params . match : params . mismatch ;\n</code></pre> <pre><code>// determine the maximum value and traceback\n\ntype_t max_value = ins ;\nwt_tbp = TB_LEFT ;\n\nif ( max_value &lt; match ) { max_value = match ;\n    wt_tbp = TB_DIAG ; \n    }\nif ( max_value &lt; del ) { max_value = del ;\n    wt_tbp = TB_UP ; \n    }\nif ( max_value &lt; ( type_t ) 0) { max_value = 0;\n    wt_tbp = TB_END ; \n    }\n\nwt_scr = max_value ;\n</code></pre>"},{"location":"index.html#step-5-specify-traceback-strategy","title":"Step 5: Specify Traceback Strategy","text":"<p>The third step after initialization and scoring logic modification of your own custom kernel is to specify the traceback logic/strategy.</p> <p>Each score matrix cell is mapped to a state, and state transitions correspond to jumps between scoring matrices. User needs to define the logic to map the current cell\u2019s state and its traceback pointer to the next cell which is called at every traceback step. </p> <p>In the Local Linear kernel example with a single state shown below, the outer if-statement checks the current state from the <code>tb_state</code> and assigns the new state. The traceback write-out port <code>wt_tbp</code> is assigned a direction to move in the score matrix, corresponding to insertion, deletion, match/mismatch, or end of the traceback.</p> <pre><code>if ( tb_state == TB_STATE :: MM ) {\n    if ( tb_ptr == TB_DIAG ) { tb_move = AL_MMI ; \n    }\n    else if ( tb_ptr == TB_UP ) { tb_move = AL_DEL ; \n    }\n    else if ( tb_ptr    == TB_LEFT ) { tb_move = AL_INS ;\n    }\n    else if ( tb_ptr == TB_END ) { tb_move = AL_END ;\n    }\n    else { tb_move = AL_END ; \n    }\n\ntb_state = TB_STATE :: MM ;\n}\n</code></pre>"},{"location":"index.html#step-6-specify-parallelism","title":"Step 6: Specify Parallelism","text":"<p>Each kernel in DP-HLS consists of N<sub>B</sub> blocks, which concurrently execute distinct pairs of input sequences, each having N<sub>PE</sub> number of PEs. These blocks are identical in terms of hardware implementation, ensuring uniform performance across all blocks. To exploit the resources for maximum throughput, DP-HLS allows multiple blocks to be executed in single hardware device. DP-HLS also allows user to integrate and execute different types of kernels (N<sub>K</sub> number of heterogenous kernels), each having N<sub>B</sub> parallel blocks. </p> <p>The parameter N<sub>PE</sub> determines the level of inner-loop parallelism for a single pair of sequences. DP-HLS exploits outer-loop parallelism across multiple sequence pairs by setting the parameters N<sub>B</sub> and N<sub>K</sub>.</p> <p>The values of N<sub>PE</sub>, N<sub>B</sub> and N<sub>K</sub> are all customizable by the users. </p>"},{"location":"index.html#build-and-simulate-new-kernels","title":"Build and simulate new kernels","text":"<p>Once the kernels are customized based on your own specific requirement, then its time to build and simulate it to verify the changes. The C-Simulation or C based simulation of the customized kernel is performed with CMake, since it enables standard C++ debugging processes and the debuggers. </p> <p>Note</p> <p>Vitis HLS also supports the C-Simulation step which uses <code>v++</code> compiler. However, we found the standard <code>c++</code> compiler to have much smaller latency in rebuilding the kernel and rerun the debugger than using the Vitis HLS.</p>"},{"location":"index.html#step-1-install-dependencies","title":"Step 1: Install Dependencies","text":"<p>To build and simulate the kernel, it is required to have <code>g++ (GCC) &gt;= 4.8.5</code> and <code>CMake3</code> installed in your system. </p> <p>Note</p> <p>If you have older version of CMake in your system, you need to install CMake3 and set it to default instead. You could follow this useful StackOverflow post to perform this step.</p>"},{"location":"index.html#step-2-create-a-testbench","title":"Step 2: Create a testbench","text":"<p>For the basic C based simulation of the customized kernel, user needs to create a simple testbench to drive the kernel at this step. A testbench should consists of the buffer and input initialization, kernel call, and output verification. Please refer to the following code for the testbench example of Global Affine kernel. Notice that you can write a similar C++ function to verify the correctness of the kernel output. </p> <pre><code>#include &lt;string&gt;\n#include &lt;vector&gt;\n#include &lt;array&gt;\n#include &lt;map&gt;\n#include &lt;chrono&gt;\n#include \"params.h\"\n#include \"seq_align_multiple.h\"\n#include \"host_utils.h\"\n#include \"solutions.h\"\n#include \"debug.h\"\n\nusing namespace std;\n\n#define INPUT_QUERY_LENGTH 256\n#define INPUT_REFERENCE_LENGTH 256\n\nchar_t base_to_num(char base)\n{\n    switch (base)\n    {\n    case 'A':\n        return 0;\n    case 'C':\n        return 1;\n    case 'G':\n        return 2;\n    case 'T':\n        return 3;\n    default:\n        return 0;\n#ifdef CMAKEDEBUG\n        throw std::runtime_error(\"Unrecognized Nucleotide \" + std::string(1, base) + \" from A, C, G, and T.\\n\"); // or throw an exception\n#endif\n    }\n\n}\n\nstruct Penalties_sol\n{\n    float extend;\n    float open;\n    float linear_gap;\n    float match;\n    float mismatch;\n};\n\nint main(){\n    char alphabet[4] = {'A', 'T', 'G', 'C'};\n    std::string query_string = Random::Sequence&lt;4&gt;(alphabet, INPUT_QUERY_LENGTH);\n    std::string reference_string = Random::Sequence&lt;4&gt;(alphabet, INPUT_REFERENCE_LENGTH);\n\n    // Struct for Penalties in kernel\n    Penalties penalties[N_BLOCKS];\n    for (int i = 0; i &lt; N_BLOCKS; i++){\n        penalties[i].extend = -1;\n        penalties[i].open = -1;\n        penalties[i].match = 3;\n        penalties[i].mismatch = -1;\n    }\n\n    // Struct for penalties in solution\n    Penalties_sol penalties_sol[N_BLOCKS];\n    for (Penalties_sol &amp;penalty : penalties_sol) {\n        penalty.extend = -1;\n        penalty.open = -1;\n        penalty.match = 3;\n        penalty.mismatch = -1;\n    }\n\n    // Reference and Query Strings\n    std::vector&lt;char&gt; query(query_string.begin(), query_string.end());\n    std::vector&lt;char&gt; reference(reference_string.begin(), reference_string.end());\n\n#ifdef CMAKEDEBUG\n    // Initialize Debugger\n    Container debuggers[N_BLOCKS];\n    for (int i = 0; i &lt; N_BLOCKS; i++){\n        debuggers[i] = Container();\n    }\n#endif\n\n    // Assert actual query length and reference length should be smaller than the maximum length\n    try {\n        if (query.size() &gt; MAX_QUERY_LENGTH) throw std::runtime_error(\"Query length should less than MAX_QUERY_LENGTH, \"\n            \"actual query len \" + std::to_string(query.size()) + \", Allocated qry len: \" + std::to_string(MAX_QUERY_LENGTH));\n        if (reference.size() &gt; MAX_REFERENCE_LENGTH) throw std::runtime_error(\"Reference length should less than MAX_REFERENCE_LENGTH, \"\n            \"actual ref len \" + std::to_string(reference.size()) + \", Allocated ref len: \" + std::to_string(MAX_REFERENCE_LENGTH));\n    } catch (const std::exception &amp;e) {\n        std::cerr &lt;&lt; \"Exception: \" &lt;&lt; e.what() &lt;&lt; std::endl;\n        throw;\n    }\n\n    // Allocate query and reference buffer to pass to the kernel\n    char_t reference_buff[MAX_REFERENCE_LENGTH][N_BLOCKS];\n    char_t query_buff[MAX_QUERY_LENGTH][N_BLOCKS];\n\n    // Allocate lengths for query and reference\n    idx_t qry_lengths[N_BLOCKS], ref_lengths[N_BLOCKS];\n\n    // Fill query buffer and references buffer for all blocks.\n    // Each buffer is of MAX size, but only the actual length\n    // elements is filled.\n    for (int b = 0; b &lt; N_BLOCKS; b++)\n    {\n        for (int i = 0; i &lt; query.size(); i++)\n        {\n            query_buff[i][b] = base_to_num(query[i]);\n        }\n        for (int i = 0; i &lt; reference.size(); i++)\n        {\n            reference_buff[i][b] = base_to_num(reference[i]);\n        }\n    }\n\n    // Fill the lengths of the query and reference\n    for (int b = 0; b &lt; N_BLOCKS; b++)\n    {\n        qry_lengths[b] = query.size();\n        ref_lengths[b] = reference.size();\n    }\n\n    // Allocate traceback streams\n    tbr_t tb_streams[MAX_REFERENCE_LENGTH + MAX_QUERY_LENGTH][N_BLOCKS];\n\n    // initialize traceback starting coordinates\n    idx_t tb_is[N_BLOCKS];\n    idx_t tb_js[N_BLOCKS];\n\n    cout &lt;&lt; \"Kernel Started\" &lt;&lt; endl;\n    // Actual kernel calling\n    seq_align_multiple_static(\n        query_buff,\n        reference_buff,\n        qry_lengths,\n        ref_lengths,\n        penalties,\n        tb_is, tb_js,\n        tb_streams\n#ifdef CMAKEDEBUG\n        , debuggers\n#endif\n        );\n\n    // Print the query and reference strings\n    cout &lt;&lt; \"Query    : \" &lt;&lt; query_string &lt;&lt; endl;\n    cout &lt;&lt; \"Reference: \" &lt;&lt; reference_string &lt;&lt; endl;\n\n    // Get the solution scores and traceback\n    array&lt;array&lt;array&lt;float, MAX_REFERENCE_LENGTH&gt;, MAX_QUERY_LENGTH&gt;, N_LAYERS&gt; sol_score_mat;\n    array&lt;array&lt;string, MAX_REFERENCE_LENGTH&gt;, MAX_QUERY_LENGTH&gt; sol_tb_mat;\n    map&lt;string, string&gt; alignments;\n    auto sol_start = std::chrono::high_resolution_clock::now();\n    global_affine_solution&lt;Penalties_sol, MAX_QUERY_LENGTH, MAX_REFERENCE_LENGTH, N_LAYERS&gt;(query_string, reference_string, penalties_sol[0], sol_score_mat, sol_tb_mat, alignments);\n    auto sol_end = std::chrono::high_resolution_clock::now();\n    // print_matrix&lt;float, MAX_QUERY_LENGTH, MAX_REFERENCE_LENGTH&gt;(sol_score_mat[0], \"Solution Score Matrix Layer 0\");\n    // print_matrix&lt;char, MAX_QUERY_LENGTH, MAX_REFERENCE_LENGTH&gt;(sol_tb_mat, \"Solution Traceback Matrix\");\n    cout &lt;&lt; \"Solution Aligned Query    : \" &lt;&lt; alignments[\"query\"] &lt;&lt; endl;\n    cout &lt;&lt; \"Solution Aligned Reference: \" &lt;&lt; alignments[\"reference\"] &lt;&lt; endl;\n    // Display solution runtime\n    std::cout &lt;&lt; \"Solution Runtime: \" &lt;&lt; std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(sol_end - sol_start).count() &lt;&lt; \"ms\" &lt;&lt; std::endl;\n\n#ifdef CMAKEDEBUG\n    // Cast kernel scores to matrix scores\n    debuggers[0].cast_scores();\n    // print_matrix&lt;float, MAX_QUERY_LENGTH, MAX_REFERENCE_LENGTH&gt;(debuggers[0].scores_cpp[0], \"Kernel 0 Scores Layer 0\");\n    debuggers[0].compare_scores(sol_score_mat, query.size(), reference.size());  // check if the scores from the kernel matches scores from the solution\n#endif\n\n    // reconstruct kernel alignments\n    array&lt;map&lt;string, string&gt;, N_BLOCKS&gt; kernel_alignments;\n    int tb_query_lengths[N_BLOCKS];\n    int tb_reference_lengths[N_BLOCKS];\n    string query_string_blocks[N_BLOCKS];\n    string reference_string_blocks[N_BLOCKS];\n    // for global alignments, adjust the lengths to be the lengths - 1\n    for (int i = 0; i &lt; N_BLOCKS; i++) {\n        tb_query_lengths[i] = (int) tb_is[i];\n        tb_reference_lengths[i] = (int) tb_js[i];\n        query_string_blocks[i] = query_string;\n        reference_string_blocks[i] = reference_string;\n    }\n    tbr_t tb_streams_host[N_BLOCKS][MAX_REFERENCE_LENGTH + MAX_QUERY_LENGTH];\n    HostUtils::IO::SwitchDimension(tb_streams, tb_streams_host);\n    kernel_alignments = HostUtils::Sequence::ReconstructTracebackBlocks&lt;tbr_t, N_BLOCKS, MAX_QUERY_LENGTH, MAX_REFERENCE_LENGTH&gt;(\n        query_string_blocks, reference_string_blocks,\n        tb_query_lengths, tb_reference_lengths, \n        tb_streams_host);\n\n    // Print kernel 0 traceback\n    for (int i = 0; i &lt; N_BLOCKS; i++) {\n        cout &lt;&lt; \"Kernel \" &lt;&lt; i &lt;&lt; \" Traceback\" &lt;&lt; endl;\n        cout &lt;&lt; \"Kernel   Aligned Query    : \" &lt;&lt; kernel_alignments[0][\"query\"] &lt;&lt; endl;\n        cout &lt;&lt; \"Kernel   Aligned Reference: \" &lt;&lt; kernel_alignments[0][\"reference\"] &lt;&lt; endl;\n    }\n}\n</code></pre> <p>Note</p> <p>This testbench is for the purpose of C simulation only and is different from the OpenCL based Host program mentioned later which is needed for the actual deployment of the kernel on FPGA.</p>"},{"location":"index.html#step-3-build-and-run","title":"Step 3: Build and Run","text":"<p>Once dependencies are installed, you need to edit the <code>CMakeLists.txt</code> provided in the GitHub repository for your own kernel target. </p> <p>For each target, you need to add the lines specifying the following:</p> <ol> <li>Common source file - <code>COMMON_SRCS</code> that is required for all the kernels. </li> <li>Testbench file. </li> <li>User defined function source. </li> </ol> <p>Then you need to add the folder containing <code>params.h</code> as a include path for your kernel. The following example shows how it should be done for global affine kernel. These lines need to be added in the <code>CMakeLists.txt</code>. Similarly, you need to do it for your own custom kernel. </p> <pre><code>add_executable(test_csim_global_affine\n    \"testbench/test_csim_global_affine.cpp\"\n    \"kernels/global_affine/kernel_global_affine.cpp\"\n    ${COMMON_SRCS})\n\ntarget_include_directories(test_csim_global_affine PRIVATE \"./kernels/global_affine\")\n</code></pre> <p>Once the <code>CMakeLists.txt</code> is configured, follow the below commands to build and run the target (i.e, your own custom kernel).</p> <pre><code>mkdir build &amp;&amp; cd build\ncmake ..\nmake &lt;target&gt; ## here the target is the kernel found in the CMakeLists.txt\n</code></pre> <p>Note</p> <p>With the CMake extension, VSCode automatically detect and configure the CMake project with the <code>CMakeLists.txt</code> provided in the repo. You can simply use the VSCode CMake extension GUI to build and run the project. </p> <p>Note</p> <p>Kernels in DP-HLS framework are tested on CentOS7 with AMD Vitis 2021.2, the OS and toolchain which comes with the AWS FPGA Developer AMI. We would suggest this platform to build and run the DP-HLS kernels because it comes with the device license in AMD Vitis and Vivado for the FPGA device on AWS F1 instances. </p> <p>If you are not using the specified AMI, then you need to set the <code>HLS_HOME</code> variable in <code>CMakeLists.txt</code> to point to the customized Vitis HLS installation path so CMake can find the correct include and link path. </p>"},{"location":"index.html#synthesize-and-deploy-new-kernels","title":"Synthesize and deploy new kernels","text":""},{"location":"index.html#step-1-write-host-side-program","title":"Step 1: Write host-side program","text":"<p>In addition to the <code>params.h</code> and your kernel function source file, you need to write a OpenCL host program to synthesize and deploy the kernel. A simple example for the host program can be found in the Vitis Examples.</p> <p>The following code shows a sample host program for your reference.</p> <pre><code>#include \"xcl2.hpp\"\n#include &lt;vector&gt;\n#include &lt;algorithm&gt;\n#include &lt;ap_int.h&gt;\n#include &lt;ap_fixed.h&gt;\n#include \"../../include/host_utils.h\"\n#include \"dp_hls_common.h\"\n#include &lt;map&gt;\n#include &lt;chrono&gt;\n\nint base_to_num(char base){\n    switch (base)\n    {\n    case 'A':\n        return 0;\n    case 'C':\n        return 1;\n    case 'G':\n        return 2;\n    case 'T':\n        return 3;\n    default:\n        return 0;\n#ifdef CMAKEDEBUG\n        throw std::runtime_error(\"Unrecognized Nucleotide \" + std::string(1, base) + \" from A, C, G, and T.\\n\"); // or throw an exception\n#endif\n    }\n}\n\n\nint main(int argc, char **argv) {\n    if (argc != 2) {\n        std::cout &lt;&lt; \"Usage: \" &lt;&lt; argv[0] &lt;&lt; \" &lt;XCLBIN File&gt;\" &lt;&lt; std::endl;\n        return EXIT_FAILURE;\n    }\n\n    std::string binaryFile = argv[1];\n    cl_int err;\n    cl::Context context;\n    cl::Kernel krnl_seq_align;\n    cl::CommandQueue q;\n\n    // Allocate memory for each array\n    std::vector&lt;char_t, aligned_allocator&lt;char_t&gt;&gt; querys(N_BLOCKS * MAX_QUERY_LENGTH);\n    std::vector&lt;char_t, aligned_allocator&lt;char_t&gt;&gt; references(N_BLOCKS * MAX_REFERENCE_LENGTH);\n    std::vector&lt;idx_t, aligned_allocator&lt;idx_t&gt;&gt; query_lengths(N_BLOCKS);\n    std::vector&lt;idx_t, aligned_allocator&lt;idx_t&gt;&gt; reference_lengths(N_BLOCKS);\n    std::vector&lt;Penalties, aligned_allocator&lt;Penalties&gt;&gt; penalties(N_BLOCKS); // Assuming a single penalties struct\n    std::vector&lt;idx_t, aligned_allocator&lt;idx_t&gt;&gt; traceback_start_is(N_BLOCKS);  // Allocate buffer for the starting row and column of the buffer\n    std::vector&lt;idx_t, aligned_allocator&lt;idx_t&gt;&gt; traceback_start_js(N_BLOCKS);\n    std::vector&lt;tbr_t, aligned_allocator&lt;tbr_t&gt;&gt; tb_streams(N_BLOCKS * (MAX_REFERENCE_LENGTH + MAX_QUERY_LENGTH));\n\n    // Initialize data\n    char alphabet[] = {'A', 'T', 'C', 'G'};  // currently putting just random sequence here\n    string querys_strings = Random::Sequence&lt;4&gt;(alphabet, N_BLOCKS * MAX_QUERY_LENGTH);\n    string references_strings = Random::Sequence&lt;4&gt;(alphabet, N_BLOCKS * MAX_REFERENCE_LENGTH);\n    const char *query_ptr = querys_strings.c_str();\n    const char *reference_ptr = references_strings.c_str();\n    for (int i = 0; i &lt; N_BLOCKS; i++) {\n        query_lengths[i] = MAX_QUERY_LENGTH;\n        reference_lengths[i] = MAX_REFERENCE_LENGTH;\n        for (int j = 0; j &lt; MAX_QUERY_LENGTH; j++) {\n            querys[i * MAX_QUERY_LENGTH + j] = (type_t) base_to_num(*query_ptr++);\n        }\n        for (int j = 0; j &lt; MAX_REFERENCE_LENGTH; j++) {\n            references[i * MAX_REFERENCE_LENGTH + j] = (type_t) base_to_num(*reference_ptr++);\n        }\n        // Initialize Penalties\n        penalties[i].open = type_t(-2);\n        penalties[i].extend = type_t(-1);\n        penalties[i].mismatch = type_t(-3);\n        penalties[i].match = type_t(2);\n        penalties[i].linear_gap = type_t(-1);\n    }\n\n    // OPENCL HOST CODE AREA START\n    auto devices = xcl::get_xil_devices();\n    auto fileBuf = xcl::read_binary_file(binaryFile);\n    cl::Program::Binaries bins{{fileBuf.data(), fileBuf.size()}};\n    bool valid_device = false;\n    for (unsigned int i = 0; i &lt; devices.size(); i++) {\n        auto device = devices[i];\n        OCL_CHECK(err, context = cl::Context(device, nullptr, nullptr, nullptr, &amp;err));\n        OCL_CHECK(err, q = cl::CommandQueue(context, device, CL_QUEUE_PROFILING_ENABLE, &amp;err));\n        std::cout &lt;&lt; \"Trying to program device[\" &lt;&lt; i &lt;&lt; \"]: \" &lt;&lt; device.getInfo&lt;CL_DEVICE_NAME&gt;() &lt;&lt; std::endl;\n        cl::Program program(context, {device}, bins, nullptr, &amp;err);\n        if (err != CL_SUCCESS) {\n            std::cout &lt;&lt; \"Failed to program device[\" &lt;&lt; i &lt;&lt; \"] with xclbin file!\\n\";\n        } else {\n            std::cout &lt;&lt; \"Device[\" &lt;&lt; i &lt;&lt; \"]: program successful!\\n\";\n            OCL_CHECK(err, krnl_seq_align = cl::Kernel(program, \"seq_align_multiple_static\", &amp;err));\n            valid_device = true;\n            break;\n        }\n    }\n    if (!valid_device) {\n        std::cout &lt;&lt; \"Failed to program any device found, exit!\\n\";\n        exit(EXIT_FAILURE);\n    }\n\n    // Allocate Buffers in Global Memory and set kernel arguments\n    OCL_CHECK(err, cl::Buffer buffer_querys(context, CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, \n                                            sizeof(char_t) * querys.size(), querys.data(), &amp;err));\n    OCL_CHECK(err, cl::Buffer buffer_references(context, CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, \n                                                sizeof(char_t) * references.size(), references.data(), &amp;err));\n    OCL_CHECK(err, cl::Buffer buffer_query_lengths(context, CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, \n                                                   sizeof(idx_t) * query_lengths.size(), query_lengths.data(), &amp;err));\n    OCL_CHECK(err, cl::Buffer buffer_reference_lengths(context, CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, \n                                                       sizeof(idx_t) * reference_lengths.size(), reference_lengths.data(), &amp;err));\n    OCL_CHECK(err, cl::Buffer buffer_penalties(context, CL_MEM_USE_HOST_PTR | CL_MEM_READ_ONLY, \n                                               sizeof(Penalties) * penalties.size(), penalties.data(), &amp;err));\n    OCL_CHECK(err, cl::Buffer buffer_traceback_start_is(context, CL_MEM_USE_HOST_PTR | CL_MEM_WRITE_ONLY,  \n                                                   sizeof(idx_t) * traceback_start_is.size(), traceback_start_is.data(), &amp;err));\n    OCL_CHECK(err, cl::Buffer buffer_traceback_start_js(context, CL_MEM_USE_HOST_PTR | CL_MEM_WRITE_ONLY, \n                                                       sizeof(idx_t) * traceback_start_js.size(), traceback_start_js.data(), &amp;err));\n    OCL_CHECK(err, cl::Buffer buffer_tb_streams(context, CL_MEM_USE_HOST_PTR | CL_MEM_WRITE_ONLY, \n                                                sizeof(tbr_t) * tb_streams.size(), tb_streams.data(), &amp;err));\n\n\n    // Set Kernel Arguments\n    OCL_CHECK(err, err = krnl_seq_align.setArg(0, buffer_querys));\n    OCL_CHECK(err, err = krnl_seq_align.setArg(1, buffer_references));\n    OCL_CHECK(err, err = krnl_seq_align.setArg(2, buffer_query_lengths));\n    OCL_CHECK(err, err = krnl_seq_align.setArg(3, buffer_reference_lengths));\n    OCL_CHECK(err, err = krnl_seq_align.setArg(4, buffer_penalties));\n    OCL_CHECK(err, err = krnl_seq_align.setArg(5, buffer_traceback_start_is));\n    OCL_CHECK(err, err = krnl_seq_align.setArg(6, buffer_traceback_start_js));\n    OCL_CHECK(err, err = krnl_seq_align.setArg(7, buffer_tb_streams));\n\n    // Copy input data to device global memory\n    auto start = std::chrono::high_resolution_clock::now();\n    OCL_CHECK(err, err = q.enqueueMigrateMemObjects({buffer_querys, buffer_references, buffer_query_lengths, \n                                                     buffer_reference_lengths, buffer_penalties}, 0 /* 0 means from host*/));\n\n    // Launch the Kernel\n    OCL_CHECK(err, err = q.enqueueTask(krnl_seq_align));\n\n\n    // Copy Result from Device Global Memory to Host Local Memory\n    OCL_CHECK(err, err = q.enqueueMigrateMemObjects({buffer_traceback_start_is, buffer_traceback_start_js, buffer_tb_streams}, CL_MIGRATE_MEM_OBJECT_HOST));\n    q.finish();\n    auto end = std::chrono::high_resolution_clock::now();\n\n    // OPENCL HOST CODE AREA END\n\n    // Print raw traceback pointer streams\n    for (int i = 0; i &lt; N_BLOCKS; i++) {\n        std::cout &lt;&lt; \"Query: \" &lt;&lt; querys_strings.substr(i * MAX_QUERY_LENGTH, MAX_QUERY_LENGTH) &lt;&lt; std::endl;\n        std::cout &lt;&lt; \"Reference: \" &lt;&lt; references_strings.substr(i * MAX_REFERENCE_LENGTH, MAX_REFERENCE_LENGTH) &lt;&lt; std::endl;\n        std::cout &lt;&lt; \"Traceback: \" &lt;&lt; std::endl;\n        for (int j = 0; j &lt; MAX_QUERY_LENGTH + MAX_REFERENCE_LENGTH; j++) {\n            std::cout &lt;&lt; tb_streams[i * (MAX_QUERY_LENGTH + MAX_REFERENCE_LENGTH) + j];\n        }\n        std::cout &lt;&lt; std::endl;\n    }\n\n    // Print time\n    std::cout &lt;&lt; \"Kernel execution time: \" &lt;&lt; std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(end - start).count() &lt;&lt; \"ms\" &lt;&lt; std::endl;\n\n    std::cout &lt;&lt; \"Kernel execution complete.\" &lt;&lt; std::endl;\n    return EXIT_SUCCESS;\n}\n</code></pre>"},{"location":"index.html#step-2-install-dependencies","title":"Step 2: Install Dependencies","text":"<p>We have provided some scripts to run the synthesis and cosimulation of the kernels. For that, you need to have <code>Python: Version &gt; 3.6</code> installed in your system. </p> <p>Kernels in DP-HLS framework are tested on CentOS7 with AMD Vitis 2021.2, the OS and toolchain which comes with the AWS FPGA Developer AMI.  You can use any AWS machine to synthesis the kernel as long as it's compatible with the FPGA developer AMI. We used 8-core Amazon EC2 z1d instances for the implementation of DP-HLS kernel.</p>"},{"location":"index.html#step-3-configure-the-project-using-json-file","title":"Step 3: Configure the project using JSON file","text":"<p>We provide a set of Python scripts with the DP-HLS repository to streamline the AMD Vitis HLS project creation, synthesis, and implementation. Those scripts are in the <code>py-hls</code> folder. </p> <p>Those scripts require JSON configuration file as input. Following example shows how to configure the JSON file with the explanation of all parameters. This JSON file below has prefilled parameters for the global affine kernel. Similarly, you need to do it for your own custom kernel.</p> <pre><code>{\n    \"size\": {\n        \"max_problem_size\": [\n            {\"max_query_length\": 256, \"max_reference_length\": 256}\n        ],\n        \"pe_num\": [4, 8, 16, 32],\n        \"blocks\": [1],\n        \"cu\": [1]\n    },\n    \"kernel\": {\n        \"name\": \"seq_align_multiple_static\",\n        \"clock_frequency\": 250000000\n    },\n    \"design\": {\n        \"path_params\": \"/home/centos/workspace/DP-HLS/compile_configs/global_affine/design\",\n        \"path_frontend\": \"/home/centos/workspace/DP-HLS/compile_configs/global_affine/design/kernel_global_affine.cpp\",\n        \"dp-hls_root\": \"/home/centos/workspace/DP-HLS\",\n        \"host_program\": \"/home/centos/workspace/DP-HLS/src/hosts/host_ocl_global.cpp\"\n    },\n    \"output_path\": \"/home/centos/workspace/DP-HLS/synthesis/results/global_affine\",\n    \"output_name\": \"global_affine_inlined\",\n    \"build\": {\n        \"build_type\": \"hw\"\n    },\n    \"vitis_hls\": {\n        \"cosim_testbench\": \"/home/centos/workspace/DP-HLS/testbench/test_csim_global_affine.cpp\",\n        \"output_path\": \"/home/centos/workspace/DP-HLS/vitis_projects/global_affine\",\n        \"export_design\": 0\n    }\n}\n</code></pre>"},{"location":"index.html#json-parameters-explained","title":"JSON Parameters Explained","text":"<ul> <li><code>size</code>: Related to the size of the kernel. <ul> <li><code>max_problem_size</code>: Defines the <code>MAX_QUERY_LENGTH</code> and <code>MAX_REFERENCE_LENGTH</code>. </li> <li><code>pe_num</code>: Number of PE in a block (N<sub>PE</sub>). </li> <li><code>blocks</code>: Number of blocks in a kernel (N<sub>B</sub>). </li> <li><code>cu</code>: Number of compute units linked in a FPGA bitsteram (N<sub>K</sub>). </li> </ul> </li> <li><code>kernel</code>: Related to the kernel name and clock frequency. <ul> <li><code>name</code>: This sets the name of your custom kernel. Currently the name <code>seq_align_mulitple_static</code> is supported. </li> <li><code>clock_frequency</code>: This sets the target clock frequency. If the design can't meet this clock frequency, then it will be lowered automatically in the kernel linking stage.</li> </ul> </li> <li><code>design</code>:<ul> <li><code>path_params</code>: Specifies the path to the folder containing the <code>params.h</code>. </li> <li><code>path_frontend</code>: Specifies the path to the front-end kernel source file. In this case, it points to <code>kernel_global_affine.cpp</code>.</li> <li><code>dp-hls_root</code>: Defines the root directory of the DP-HLS library. </li> <li><code>host_program</code>: Points to the source file of the OpenCL host program that manages kernel execution on the FPGA.</li> </ul> </li> <li><code>output_path</code>: Specifies the output directory for generated RTL code, reports, and log files. </li> <li><code>output_name</code>: Defines the base name for the output files generated during the synthesis process. In this example, the output files will be prefixed with <code>global_affine_inlined</code>.</li> <li><code>build</code>: Related to the build configuration for the Vitis project. The <code>build_type</code> can be <code>sw_emu</code>, <code>hw_emu</code>, or <code>hw</code> which is equivalent to the three <code>TARGETS</code> described in the <code>aws-fpga</code> repo. </li> <li><code>vitis_hls</code>: Contains settings specific to using the Vitis HLS toolchain.<ul> <li><code>cosim_testbench</code>: Specifies the path to the C++ testbench file used for co-simulation.</li> <li><code>output_path</code>: Indicates the output directory of the Vitis HLS project. This is separate from the bitstream output path specified in the <code>output_path</code> above. </li> <li><code>export_design</code>: A flag indicating whether the design should be exported after synthesis. A value of <code>0</code> means the design will not be exported, while <code>1</code> would run the implementation and gives the post-route utilization number.</li> </ul> </li> </ul> <p>With the JSON config file above, you can compile a batch of kernels with the full combinations of <code>max_problem_size</code> x <code>pe_num</code> x <code>blocks</code> x <code>kernels</code> with the naming convention <code>&lt;name&gt;_&lt;max_query_length&gt;_&lt;max_reference_length&gt;_&lt;pe_num&gt;_&lt;blocks&gt;_&lt;kernels&gt;</code> in the output directory. For example, if the <code>size</code> is:  <pre><code>\"size\": {\n    \"max_problem_size\": [\n        {\"max_query_length\": 256, \"max_reference_length\": 256}\n    ],\n    \"pe_num\": [16, 32],\n    \"blocks\": [8, 16],\n    \"cu\": [1]\n}\n</code></pre> Then the output director would contains the following folders, each one containing everything compile-related for that specific kernel configuration: <pre><code>output_dir/                      \n\u251c\u2500\u2500 global_affine_256_256_16_8_1\n\u251c\u2500\u2500 global_affine_256_256_16_16_1\n\u251c\u2500\u2500 global_affine_256_256_32_8_1\n\u2514\u2500\u2500 global_affine_256_256_32_16_1\n</code></pre></p>"},{"location":"index.html#step-4-synthesize-the-kernel_1","title":"Step 4: Synthesize the kernel","text":"<p>To run the python script which streamline the AMD Vitis HLS project creation, synthesis, and implementations, run the following command:</p> <pre><code>python py-hls/auto_cosim.py --config &lt;path_to_the_json_config&gt; --simulate True\n</code></pre>"},{"location":"index.html#explaining-command-line-arguments","title":"Explaining command-line arguments","text":"<ul> <li><code>--config</code>: Specify the path of the configured JSON file</li> <li><code>--simulate</code>: Set to <code>True</code> if you need to perform the co-simulation step along with the synthesis step of the Vitis HLS design flow. Set to <code>False</code> if only synthesis step is needed to be performed.</li> </ul>"},{"location":"index.html#step-4-analyze-the-implementation-output","title":"Step 4: Analyze the implementation output","text":"<p>After executing the python script which perform synthesis and co-simulation step of the Vitis HLS design flow, several output files will be created. Following shows the file structure for all the output files saved in the output directory for the global affine kernel (some non-essential files are not shown here). <pre><code>output_dir/                      \n\u251c\u2500\u2500 global_affine_256_256_16_8_1/                 \n\u2502   \u251c\u2500\u2500 _x.hw.xilinx_aws-vu9p-f1_shell-v04261818_201920_3/\n\u2502   \u251c\u2500\u2500 build_dir.hw.xilinx_aws-vu9p-f1_shell-v04261818_201920_3/\n\u2502   \u251c\u2500\u2500 report/  \n|   \u251c\u2500\u2500 dp-hls-host\n|   \u251c\u2500\u2500 Makefile\n|   \u251c\u2500\u2500 parallel_compile_error.log         \n\u2502   \u2514\u2500\u2500 parallel_compile_output.log\n\u251c\u2500\u2500 global_affine_256_256_16_16_1\n\u251c\u2500\u2500 global_affine_256_256_32_8_1\n\u2514\u2500\u2500 global_affine_256_256_32_16_1\n</code></pre></p>"},{"location":"index.html#details-of-the-output-files-generated","title":"Details of the output files generated","text":"<ul> <li><code>build_dir.hw.xilinx_aws-vu9p-f1_shell-v04261818_201920_3</code> contains the output <code>.xclbin</code> bitstream file, which later on needed to be used to create the AFI. </li> <li>Detailed synthesis and implementation report (place and route) as well as the logs can be found under <code>_x.hw.xilinx_aws-vu9p-f1_shell-v04261818_201920_3</code>.<ul> <li>Detailed Synthesis Report found in: <code>_x.hw.xilinx_aws-vu9p-f1_shell-v04261818_201920_3/seq_align_kernel/seq_align_multiple_static/seq_align_multiple_static/solution/syn/report</code></li> <li>Synthesized Verilog source file found in: <code>_x.hw.xilinx_aws-vu9p-f1_shell-v04261818_201920_3/seq_align_kernel/seq_align_multiple_static/seq_align_multiple_static/solution/impl/verilog</code></li> <li>Logs found in: <code>_x.hw.xilinx_aws-vu9p-f1_shell-v04261818_201920_3/logs</code></li> </ul> </li> <li><code>report</code> folder contains synthesis and place and route summary. </li> <li><code>Makefile</code> contains the the original make file used to compile the kernel. </li> <li><code>parallel_compile_error.log</code> contains the compile error collected from the <code>stderr</code> for this specific kernel. </li> <li><code>parallel_compile_output.log</code> contains the compile output collected from the <code>stdout</code> for this specific kernel. </li> </ul>"},{"location":"index.html#analyze-the-output-using-gui","title":"Analyze the output using GUI","text":"<p>To inspect the reports of Vitis HLS Co-Simulation and Implementation visually using GUI, please open Vitis HLS GUI and select \"open project\" to open the folder <code>global_affine_256_256_16_8_1</code> under the path specified for <code>vitis_hls/output_path</code> in the config (different from the compile output path). Then you can find the time line trace for the cosimulation as well as the implementation (if <code>export_design=1</code> in <code>config.json</code>) resource utilization and timing. </p> Co-Simulation Timeline Trace view in Vitis HLS GUI for Global Affine kernel (N<sub>PE</sub>=16 and N<sub>B</sub>=8)"},{"location":"index.html#step-5-generate-the-bitstream","title":"Step 5: Generate the bitstream","text":"<p>Once the kernel is synthesized and co-simulated, run the following command to generate the bitstream:  <pre><code>python py-hls/parallel_compile.py --config &lt;path_to_the_json_config&gt; --compile True --num_workers &lt;workers&gt; --all True\n</code></pre> The flags for this script is explained below: </p> <ul> <li><code>config</code>: Specify the path to the JSON configuration file mentioned above.</li> <li><code>compile</code>: Specify whether to compile the project or not. If set to <code>False</code>, only the Makefile is created. </li> <li><code>num_workers</code>: Specify the number of parallel compilation jobs when compiling for a batch of different kernel configs. The number depends on the available device resources. Too many parallel jobs would result in some kernel's compilation killed. </li> <li><code>all</code>: Specify whether to compile everything for the kernel or not, including the host and the kernel. If set to <code>False</code>, then only the host is compiled. If set to <code>True</code>, then both host and kernel is compiled.</li> </ul> <p>Note</p> <p>The compilation could take very long time, and you can verify the progress of the kernel compilation by inspecting the <code>v++</code> log file. Normally the compilation are put to the background, <code>tmux</code> perferrably. </p>"},{"location":"index.html#step-6-deploy-the-kernel-on-aws-f1-fpga","title":"Step 6: Deploy the kernel on AWS F1 FPGA","text":"<p>With the <code>.xclbin</code> bitstream file generated and the host program written (mentioned in step 1), your custom kernel is now ready to be deployed. </p> <p>If the custom kernels' bitstream and the host program are built on another system/AWS instance other than AWS F1 FPGA instance, you can share those files with the AWS F1 instance through EFS. </p> <p>Once the bitstream is available on AWS F1 FPGA instance, follow the following steps for the deployment. This standard process is also well described in the Step 2 in Vitis Section of the AWS FPGA repo. </p> <ol> <li>Create an F1 instance with the AWS FPGA Developer AMI. </li> <li>Create AFI then wait until it's status is ready. </li> <li>Run the kernel by calling the OpenCL host and pass-in the <code>.awsxclbin</code> bitstream. </li> </ol>"},{"location":"index.html#source-code-documentation","title":"Source Code Documentation","text":"<p>To refer to the details of the source code for using the DP-HLS framework efficiently, please refer to Source Code Documentation</p>"},{"location":"index.html#contributions","title":"Contributions","text":"<p>We welcome contributions from the community. If you encounter any issues or have suggestions for improvement, please open an issue on GitHub. For general inquiries and support, reach out to our team.</p>"},{"location":"index.html#citing-dp-hls","title":"Citing DP-HLS","text":"<p>If you use DP-HLS in your research or publications, please cite the following paper:</p> <p>Y. Cao, A. Gupta, J. Liang, and Y. Turakhia, \u201cDP-HLS: A high-level synthesis framework for accelerating dynamic programming algorithms in bioinformatics,\u201d 2024. [Online]. Available: https://arxiv.org/abs/2411.03398</p>"}]}